[{"id": "autoencoder", "term": "Autoencoder", "definition": "An Autoencoder is a neural network that, when trained on unlabelled data, learns to map a high dimensional input space into a lower dimensional output space.\n"}, {"id": "automatic-differentiation", "term": "Automatic Differentiation"}, {"id": "class-saliency-map", "links": [["Original Paper", "https://arxiv.org/abs/1312.6034"]], "term": "Class Saliency Map", "definition": "A class saliency map is a visualization used to debug image classifiers. Given an input image and a class, the map shows, for each pixel in the input image, how much does that pixel contribute to the final class score. The class saliency map is computed by taking the gradient of the the class score relative to the pixel values of the input image.\n"}, {"id": "dagger", "links": [["Original Paper", "https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf"]], "term": "DAGGER (Dataset Aggregation)"}, {"id": "generative-adversarial-network", "aliases": ["GAN"], "term": "Generative Adversarial Network"}, {"id": "infogan", "term": "InfoGAN"}, {"id": "mnist", "links": [["MNIST Database", "http://yann.lecun.com/exdb/mnist/"]], "term": "MNIST", "definition": "The MNIST database is a collection of images of handwritten digits, which can be used for training neural networks. The dataset has 60,000 training examples and 10,000 test examples.\n"}, {"id": "nonstationary-policy", "term": "Non-Stationary Policy"}, {"id": "policy", "term": "Policy"}, {"id": "regret", "term": "Regret"}, {"id": "softmax", "term": "Softmax"}, {"id": "stationary-policy", "term": "Stationary Policy"}, {"id": "stochastic-policy", "term": "Stochastic Policy"}, {"id": "style-transfer", "term": "Style Transfer"}, {"id": "support-vector-machines", "term": "Support Vector Machines"}, {"id": "variational-autoencoder", "aliases": ["VAE"], "term": "Variational Autoencoder"}]